{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a9130e-8cf4-4f9a-8115-7c2e037a92a1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309c042a-430c-4df6-a5f3-1c9e3f58c075",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndimage\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import glob\n",
    "import time\n",
    "import scipy\n",
    "import random\n",
    "import pathlib\n",
    "import warnings\n",
    "import os,shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras import layers\n",
    "from skimage import io, color, feature\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, LeakyReLU, BatchNormalization, Activation\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45d12f-7d22-4d63-aa9d-7e20fb0f71cf",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311db904-48d2-4c94-a471-8889d1ff3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = pathlib.Path(\"dataset/Train\")\n",
    "test_data_dir = pathlib.Path(\"dataset/Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094bf5e-4eea-4265-8369-f41069bc2c44",
   "metadata": {},
   "source": [
    "# Counting Test and Train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c72070-39f9-46eb-a185-1a8f0fd5ba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 2239\n",
      "Test images: 118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_count_train = len(list(train_data_dir.glob('*/*.jpg')))\n",
    "print(\"Train images:\", image_count_train)\n",
    "image_count_test = len(list(test_data_dir.glob('*/*.jpg')))\n",
    "print(\"Test images:\", image_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844934fd-7ef0-4131-bef9-7dc12776b668",
   "metadata": {},
   "source": [
    "# Counting images from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e312a2b7-73a3-40da-8d19-907da27dc7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Class Name  Train Images  Test Images\n",
      "0           actinic keratosis           114           16\n",
      "1        basal cell carcinoma           376           16\n",
      "2              dermatofibroma            95           16\n",
      "3                    melanoma           438           16\n",
      "4                       nevus           357           16\n",
      "5  pigmented benign keratosis           462           16\n",
      "6        seborrheic keratosis            77            3\n",
      "7     squamous cell carcinoma           181           16\n",
      "8             vascular lesion           139            3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_names = sorted([dir.name for dir in train_data_dir.glob('*')])\n",
    "\n",
    "class_names_list = []\n",
    "train_counts = []\n",
    "test_counts = []\n",
    "for class_name in class_names:\n",
    "    train_class_dir = train_data_dir / class_name\n",
    "    test_class_dir = test_data_dir / class_name\n",
    "\n",
    "    train_count = len(list(train_class_dir.glob('*.jpg')))\n",
    "    test_count = len(list(test_class_dir.glob('*.jpg')))\n",
    "\n",
    "    class_names_list.append(class_name)\n",
    "    train_counts.append(train_count)\n",
    "    test_counts.append(test_count)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "data = {\n",
    "    \"Class Name\": class_names_list,\n",
    "    \"Train Images\": train_counts,\n",
    "    \"Test Images\": test_counts\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65b2e5-0794-49df-8a72-f993533e6460",
   "metadata": {},
   "source": [
    "# Visualization of Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f175f6e-8b31-46be-9aea-03ad7c109f5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m categories \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m counts \u001b[38;5;241m=\u001b[39m [image_count_train, image_count_test]\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(categories, counts, color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "image_count_train = len(list(train_data_dir.glob('*/*.jpg')))\n",
    "image_count_test = len(list(test_data_dir.glob('*/*.jpg')))\n",
    "\n",
    "categories = ['Train', 'Test']\n",
    "counts = [image_count_train, image_count_test]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(categories, counts, color=['blue', 'red'])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Image Count')\n",
    "plt.title('Train vs. Test Image Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3bc2a4-1cc7-484f-b574-e8a94aaca498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'Cancerous' to categorize conditions as cancerous or non-cancerous\n",
    "df['Cancerous'] = df['Class Name'].apply(lambda x: 'Cancerous' if x in ['melanoma', 'basal cell carcinoma', 'squamous cell carcinoma'] else 'Non-Cancerous')\n",
    "\n",
    "# Counting the number of cancerous and non-cancerous conditions in the training set\n",
    "train_cancerous_count = df[df['Cancerous'] == 'Cancerous']['Train Images'].sum()\n",
    "train_non_cancerous_count = df[df['Cancerous'] == 'Non-Cancerous']['Train Images'].sum()\n",
    "\n",
    "# Counting the number of cancerous and non-cancerous conditions in the test set\n",
    "test_cancerous_count = df[df['Cancerous'] == 'Cancerous']['Test Images'].sum()\n",
    "test_non_cancerous_count = df[df['Cancerous'] == 'Non-Cancerous']['Test Images'].sum()\n",
    "\n",
    "# Calculating the total counts of cancerous and non-cancerous conditions\n",
    "total_cancerous_count = train_cancerous_count + test_cancerous_count\n",
    "total_non_cancerous_count = train_non_cancerous_count + test_non_cancerous_count\n",
    "\n",
    "print(\"Cancerous Skin Conditions (Train):\", train_cancerous_count)\n",
    "print(\"Non-Cancerous Skin Conditions (Train):\", train_non_cancerous_count)\n",
    "print(\"Cancerous Skin Conditions (Test):\", test_cancerous_count)\n",
    "print(\"Non-Cancerous Skin Conditions (Test):\", test_non_cancerous_count)\n",
    "print(\"Total Cancerous Skin Conditions:\", total_cancerous_count)\n",
    "print(\"Total Non-Cancerous Skin Conditions:\", total_non_cancerous_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa82171-fb3e-4e97-b499-4b0d495babcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Train (Cancerous)', 'Train (Non-Cancerous)', 'Test (Cancerous)', 'Test (Non-Cancerous)']\n",
    "counts = [train_cancerous_count, train_non_cancerous_count, test_cancerous_count, test_non_cancerous_count]\n",
    "\n",
    "# Calculating total counts\n",
    "total_cancerous_count = train_cancerous_count + test_cancerous_count\n",
    "total_non_cancerous_count = train_non_cancerous_count + test_non_cancerous_count\n",
    "total_counts = [total_cancerous_count, total_non_cancerous_count, total_cancerous_count, total_non_cancerous_count]\n",
    "\n",
    "# Stacked horizontal bar chart\n",
    "plt.figure(figsize=(8, 4))\n",
    "bottom = [0, 0, 0, 0]\n",
    "colors = ['red', 'blue', 'red', 'blue']\n",
    "bar_width = 0.5\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    plt.barh(categories[i], counts[i], height=bar_width, left=bottom[i], color=colors[i], label=categories[i])\n",
    "    bottom[i] += counts[i]\n",
    "\n",
    "plt.title('Skin Condition Counts (Train and Test)')\n",
    "plt.ylabel('Category')\n",
    "plt.xlabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092639f9-f1bc-4755-92cf-1edf605a532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random dispay of cancerous images\n",
    "plt.figure(figsize=(10, 10))\n",
    "cancerous_indices = [i for i, class_name in enumerate(class_names) if class_name in ['melanoma', 'basal cell carcinoma', 'squamous cell carcinoma']]\n",
    "\n",
    "for i, idx in enumerate(cancerous_indices):\n",
    "    plt.subplot(3, 3, i + 4)\n",
    "    class_dir = random.choice(list(train_data_dir.glob(class_names[idx] + '/*.jpg')))\n",
    "    image = plt.imread(str(class_dir))\n",
    "    plt.title(class_names[idx])\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4dc9ed-3b12-4a9e-a9a2-fe22b8fd7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random display of non-cancerous images\n",
    "plt.figure(figsize=(10, 10))\n",
    "non_cancerous_indices = [i for i in range(len(class_names)) if i not in cancerous_indices]\n",
    "\n",
    "for i, idx in enumerate(non_cancerous_indices):\n",
    "    plt.subplot(3, 3, i + 4)\n",
    "    class_dir = random.choice(list(train_data_dir.glob(class_names[idx] + '/*.jpg')))\n",
    "    image = plt.imread(str(class_dir))\n",
    "    plt.title(class_names[idx])\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc898a3-4688-43d3-b5c1-18b3319bb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    class_dir = random.choice(list(train_data_dir.glob(class_names[i] + '/*.jpg')))\n",
    "    image = plt.imread(str(class_dir))\n",
    "    plt.title(class_names[i])\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34698f88-7b24-4f6f-8cdc-b8679279f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = [\"Train Images\", \"Test Images\" ]\n",
    "\n",
    "def plot_bar_chart(column):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(data=df, y='Class Name', x=column, orient ='h')\n",
    "    plt.title(f\"Count of {column} per Class\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Class Name\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for column in columns_to_plot:\n",
    "    plot_bar_chart(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899ee41-9539-444c-950e-ebe6f04ddf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram(data, title, color):\n",
    "    plt.hist(data, bins=20, color=color, alpha=0.7)\n",
    "    plt.xlabel(title)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {title}s')\n",
    "\n",
    "# Defining subdirectories\n",
    "subdirectories = [train_data_dir, test_data_dir]\n",
    "\n",
    "image_widths = []\n",
    "image_heights = []\n",
    "\n",
    "for subset_dir in subdirectories:\n",
    "    subset_name = os.path.basename(subset_dir)\n",
    "    classes = os.listdir(subset_dir)\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(subset_dir, class_name)\n",
    "        sample_images = os.listdir(class_dir)\n",
    "\n",
    "        for image_name in sample_images:\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            height, width = img.shape[:2]\n",
    "            image_widths.append(width)\n",
    "            image_heights.append(height)\n",
    "\n",
    "# Creating histograms for image widths and heights\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "create_histogram(image_widths, 'Image Width', 'blue')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "create_histogram(image_heights, 'Image Height', 'red')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6a521-a9cf-436a-a1c3-7c59005ac52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hexbin(x=image_widths, y=image_heights, gridsize=20, cmap='Reds', vmin=0, vmax=100)\n",
    "plt.xlabel('Image Width')\n",
    "plt.ylabel('Image Height')\n",
    "plt.title('Hexbin Plot of Image Dimensions (Width vs. Height)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5d5f6-9a80-40c4-a0a5-62a0de5d0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classes in the data directory\n",
    "classes = os.listdir(train_data_dir)\n",
    "\n",
    "feature_vectors = []\n",
    "class_labels = []\n",
    "\n",
    "def extract_features(image):\n",
    "    resized_image = cv2.resize(image, (64, 64))\n",
    "    feature_vector = resized_image.flatten()\n",
    "    return feature_vector\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(train_data_dir, class_name)\n",
    "    sample_images = os.listdir(class_dir)\n",
    "\n",
    "    for image_name in sample_images:\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        feature_vector = extract_features(img)\n",
    "\n",
    "        feature_vectors.append(feature_vector)\n",
    "        class_labels.append(i)\n",
    "\n",
    "# Standardizing the features vectors (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "feature_vectors = scaler.fit_transform(feature_vectors)\n",
    "\n",
    "# Applying t-SNE to reduce dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_features = tsne.fit_transform(feature_vectors)\n",
    "\n",
    "# Creating a scatter plot to visualize class separation\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embedded_features[:, 0], embedded_features[:, 1], c=class_labels, cmap='viridis')\n",
    "plt.title(\"t-SNE Visualization of Class Separation\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db61fe9-cc63-4142-bd9b-7526d92c4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class folders containing images\n",
    "class_folders = os.listdir(train_data_dir)\n",
    "\n",
    "# GLCM properties to calculate\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "\n",
    "# Creating an empty dictionary to store histograms for each property\n",
    "property_histograms = {prop: [] for prop in properties}\n",
    "\n",
    "# Calculating GLCM Features for Each Image in Each Class:\n",
    "for folder in class_folders:\n",
    "    class_path = os.path.join(train_data_dir, folder)\n",
    "    image_files = os.listdir(class_path)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = io.imread(image_path)\n",
    "        gray_image = color.rgb2gray(image)\n",
    "        gray_image = (gray_image * 255).astype(np.uint8)\n",
    "        glcm = graycomatrix(gray_image, [1], [0], symmetric=True, normed=True)\n",
    "        features = [feature.graycoprops(glcm, prop)[0, 0] for prop in properties]\n",
    "\n",
    "        for prop, feature_value in zip(properties, features):\n",
    "            property_histograms[prop].append((folder, feature_value))\n",
    "\n",
    "# Creating subplots for each property\n",
    "num_properties = len(properties)\n",
    "fig, axes = plt.subplots(1, num_properties, figsize=(20, 5))\n",
    "for i, prop in enumerate(properties):\n",
    "    ax = axes[i]\n",
    "    ax.set_xlabel(prop.capitalize())\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{prop.capitalize()} Histograms')\n",
    "\n",
    "    # Plotting histograms for each class\n",
    "    for folder in class_folders:\n",
    "        subset = [value for label, value in property_histograms[prop] if label == folder]\n",
    "        ax.hist(subset, bins=20, alpha=0.5, label=folder)\n",
    "\n",
    "    ax.legend(title='Class')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9061cc9-aeaf-473e-9b42-fcf070eea8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of random images to display\n",
    "num_images_to_display = 4\n",
    "\n",
    "# Create a function to plot color channels\n",
    "def plot_color_channels(image, class_name):\n",
    "    # Convert BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Split the image into color channels\n",
    "    blue_channel, green_channel, red_channel = cv2.split(image)\n",
    "\n",
    "    # Create subplots for displaying color channels\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(class_name)\n",
    "    axes[0].axis(\"off\")\n",
    "    for i, (channel, cmap_name) in enumerate(zip([red_channel, green_channel, blue_channel], ['Reds', 'Greens', 'Blues'])):\n",
    "        axes[i+1].imshow(channel, cmap=cmap_name)\n",
    "        axes[i+1].set_title(f\"{class_name} - {cmap_name.split('_')[0].capitalize()} Channel\")\n",
    "        axes[i+1].axis(\"off\")\n",
    "\n",
    "# Loop to display random images with color channels for three different classes\n",
    "for i in range(3):  # Iterate over three different class indices\n",
    "    # Get a list of image files in the class directory\n",
    "    class_dir = list(train_data_dir.glob(class_names[i] + '/*.jpg'))\n",
    "\n",
    "    if not class_dir:\n",
    "        # Handle the case where there are no images in the directory\n",
    "        print(f\"No images found in the {class_names[i]} directory.\")\n",
    "    else:\n",
    "        # Choose a random image from the list\n",
    "        random_image = random.choice(class_dir)\n",
    "        image = cv2.imread(str(random_image))\n",
    "\n",
    "        # Call the function to plot color channels\n",
    "        plot_color_channels(image, class_names[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64243596-cd44-47fd-8edd-9c3ee355600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'dataset/Train'\n",
    "# Creating a pattern to match image files (e.g., all files ending with '.jpg')\n",
    "image_pattern = '*.jpg'\n",
    "\n",
    "# list of class subdirectories\n",
    "class_directories = glob.glob(base_directory + '*/')\n",
    "\n",
    "\n",
    "for class_dir in class_directories:\n",
    "    class_name = os.path.basename(os.path.normpath(class_dir))\n",
    "    image_paths = glob.glob(class_dir + image_pattern)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Loading an image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "       # Converting the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Computing histogram of grayscale pixel intensities\n",
    "hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(gray_image.ravel(), bins=256, range=(0, 256), density=True, color='b', alpha=0.6)\n",
    "plt.title('Grayscale Pixel Intensity Distribution')\n",
    "plt.xlabel('Pixel Value')\n",
    "plt.ylabel('Normalized Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d0bd3-d2dc-496f-8d6f-27c53c282942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the destination directories for the training and validation sets\n",
    "training_data_dir = pathlib.Path(\"dataset/split_data/Training_set\")\n",
    "validation_data_dir = pathlib.Path(\"dataset/split_dat/Validation_set\")\n",
    "\n",
    "# Creating the destination directories\n",
    "training_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "validation_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_dirs = [dir.name for dir in test_data_dir.glob('*')]\n",
    "\n",
    "# Splitting the data into training and validation sets while maintaining the original directory structure\n",
    "for class_dir in class_dirs:\n",
    "    class_images = list((train_data_dir / class_dir).glob('*.jpg'))\n",
    "    train_images, val_images = train_test_split(class_images, test_size=0.4, random_state=123)\n",
    "    (training_data_dir / class_dir).mkdir(parents=True, exist_ok=True)\n",
    "    (validation_data_dir / class_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copying the images to their respective directories\n",
    "    for train_image in train_images:\n",
    "        shutil.copy(train_image, training_data_dir / class_dir / train_image.name)\n",
    "\n",
    "    for val_image in val_images:\n",
    "        shutil.copy(val_image, validation_data_dir / class_dir / val_image.name)\n",
    "\n",
    "print(\"Data splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de045c-77bd-4635-abf0-14591fe2c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Count for created Training_set, Validation_set and Original Test\n",
    "image_count_training = len(list(training_data_dir.glob('*/*.jpg')))\n",
    "print(\"Training images:\", image_count_training)\n",
    "image_count_validation = len(list(validation_data_dir.glob('*/*.jpg')))\n",
    "print(\"Validation images:\", image_count_validation)\n",
    "image_count_test = len(list(test_data_dir.glob('*/*.jpg')))\n",
    "print(\"Test images:\", image_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a6a21-058a-4d4a-814f-70cb3b1447aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming data in the directory split/train (1574 images)\n",
    "batch_size =32\n",
    "class_mode = 'categorical'\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        training_data_dir,\n",
    "        target_size=(64, 64), batch_size = batch_size, class_mode = class_mode)\n",
    "\n",
    "# transforming  data in the directory split/validation (677 images)\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(64, 64), batch_size = batch_size, class_mode = class_mode)\n",
    "\n",
    "# tranforming the data in the directory test (118 images)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(64, 64), batch_size=batch_size, class_mode = class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55f9ef-9252-4414-b1bf-875ced85a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class labels and counts for the training set\n",
    "class_labels = train_generator.class_indices\n",
    "class_counts = train_generator.classes\n",
    "\n",
    "# Calculating the number of samples in each class\n",
    "unique_classes, class_counts = np.unique(class_counts, return_counts=True)\n",
    "\n",
    "# Mapping class labels to class names\n",
    "class_names = {v: k for k, v in class_labels.items()}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_names.values(), class_counts)\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc1b2f-f98c-4c00-b0e1-986973d96426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "def create_and_train_model(model_number, train_generator, val_generator):\n",
    "    # Creating the model layers\n",
    "    np.random.seed(123)\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same',\n",
    "                            input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (4, 4), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "    # Training the model without early stopping\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs=100,\n",
    "                        validation_data=val_generator)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff927b-f154-48c5-b0b4-5a145e3df37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model1, history1 = create_and_train_model(1, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a744f2-042c-4709-a1cc-29fadd104bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"CNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bc7f1-47db-42e4-9455-32071e5d1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved baseline model\n",
    "baseline_model = load_model(\"CNN_model.h5\")\n",
    "\n",
    "# Visualize the loaded baseline model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Plot the baseline model architecture\n",
    "plot_model(baseline_model, to_file='baseline_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1170d13-dc79-4127-9aa3-177358311552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us have a close look at precision of the above model\n",
    "precision = model1.evaluate(train_generator, verbose=1)[2]\n",
    "precision_v = model1.evaluate(val_generator, verbose=1)[2]\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Validation Precision: \", precision_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348549ac-b559-4d6a-8c4d-5e669a4efbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print available keys in history to identify actual metric names\n",
    "print(\"Available keys in history:\", history1.history.keys())\n",
    "\n",
    "# Accessing loss and accuracy (fixed names)\n",
    "training_loss = history1.history['loss']\n",
    "validation_loss = history1.history['val_loss']\n",
    "training_accuracy = history1.history['accuracy']\n",
    "validation_accuracy = history1.history['val_accuracy']\n",
    "\n",
    "# Detect correct precision and recall keys\n",
    "precision_key = [k for k in history1.history.keys() if 'precision' in k and not 'val' in k][0]\n",
    "val_precision_key = [k for k in history1.history.keys() if 'val_precision' in k][0]\n",
    "recall_key = [k for k in history1.history.keys() if 'recall' in k and not 'val' in k][0]\n",
    "val_recall_key = [k for k in history1.history.keys() if 'val_recall' in k][0]\n",
    "\n",
    "# Accessing precision and recall values\n",
    "training_precision = history1.history[precision_key]\n",
    "validation_precision = history1.history[val_precision_key]\n",
    "training_recall = history1.history[recall_key]\n",
    "validation_recall = history1.history[val_recall_key]\n",
    "\n",
    "# Number of epochs\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, training_loss, 'b-', label='Train Loss')\n",
    "plt.plot(epochs, validation_loss, 'r-', label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy, Precision, Recall\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, training_accuracy, 'b-', label='Train Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, 'r-', label='Val Accuracy')\n",
    "plt.plot(epochs, training_precision, 'g-', label='Train Precision')\n",
    "plt.plot(epochs, validation_precision, 'c-', label='Val Precision')\n",
    "plt.plot(epochs, training_recall, 'm-', label='Train Recall')\n",
    "plt.plot(epochs, validation_recall, 'y-', label='Val Recall')\n",
    "plt.title('Training and Validation Metrics')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cb0e4-9c4c-4ccc-ab7c-8b2735d4a79b",
   "metadata": {},
   "source": [
    "## VGG16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc65e9-00ef-4827-85d4-981d1d6bc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',                # Replace with your actual path\n",
    "    target_size=(224, 224),         # IMPORTANT: Must match VGG16 input\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'dataset/test',                  # Replace with your actual path\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d606a-1740-48a8-b8cf-ecc93b999946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(123)\n",
    "\n",
    "# Load base VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "# Create model\n",
    "model4 = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(9, activation='softmax')  # 9 class labels\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model4.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "model4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc28e0-670a-41c7-964b-1a4a14e7c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history4 = model4.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde09096-6c32-4880-9f24-d89dc2a5cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('CNN_model.h5')  # Update this path if different\n",
    "\n",
    "# Updated class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# Image preprocessing\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Predict and display\n",
    "def predict_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    img_array = preprocess_image(file_path)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "\n",
    "    # Show image and result\n",
    "    img = Image.open(file_path).resize((200, 200))\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "    image_label.config(image=img_tk)\n",
    "    image_label.image = img_tk\n",
    "    result_label.config(text=f\"Prediction: {predicted_class}\")\n",
    "\n",
    "# GUI setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Skin Disease Classifier - Manual Test\")\n",
    "window.geometry(\"420x450\")\n",
    "\n",
    "Button(window, text=\"Choose Image and Predict\", command=predict_image, font=(\"Arial\", 12), bg=\"#add8e6\").pack(pady=20)\n",
    "image_label = Label(window)\n",
    "image_label.pack(pady=10)\n",
    "result_label = Label(window, text=\"\", font=(\"Arial\", 13, \"bold\"))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670303b5-6ddb-477d-b356-b4294131b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71c7d2-440e-43b1-bcc7-41588a2ea1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03387b02-c234-4e0f-adae-8cdb3f7d27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b64f6-4775-4d63-ae03-073c03f2833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7a090-2184-4c1f-aa50-0d4eb6d1979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff2b02-1388-4701-9620-a46bd0ff57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02eb462-3854-4e9d-b17d-43b1d814c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d0c91-e498-41bd-b5d0-eda29c1b5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "# Hide the Tkinter root window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('CNN_model.h5')\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"dermatofibroma\",\n",
    "    \"melanoma\",\n",
    "    \"nevus\",\n",
    "    \"pigmented benign keratosis\",\n",
    "    \"seborrheic keratosis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"vascular lesion\"\n",
    "]\n",
    "\n",
    "# File picker dialog\n",
    "file_path = filedialog.askopenfilename(title=\"Select a skin image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "\n",
    "if file_path:\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(Image.open(file_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253f5c9-801d-44c4-ab41-aef4e2455467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
